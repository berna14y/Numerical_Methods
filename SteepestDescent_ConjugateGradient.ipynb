{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EeGVNHSWh9TK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ZP10aZiiF6w"
   },
   "outputs": [],
   "source": [
    "A=toeplitz([2,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0rU-QGUQiMwf"
   },
   "outputs": [],
   "source": [
    "x0=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "b=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_HEBm6qyXK8G"
   },
   "outputs": [],
   "source": [
    "def steepest_descent(A, b, x0, tol=1e-6, max_iter=100):\n",
    "\n",
    "    x = x0.copy()\n",
    "    r = b - A.dot(x)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Ar = A.dot(r)\n",
    "        # Calculate the step size alpha\n",
    "        alpha = np.sqrt(r.dot(r)) / r.dot(Ar)\n",
    "         # Update the solution vector x\n",
    "        x += alpha * r\n",
    "        \n",
    "        # Check if the residual is below the convergence threshold\n",
    "        if np.sqrt(r.dot(r)) < tol:\n",
    "            break\n",
    "        # Update the search direction r    \n",
    "        r -= alpha * Ar\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSTzIJqLXg8k",
    "outputId": "61722b59-0c84-4eed-b3d9-485537ef1e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.24286166, 14.37507619, 21.3594872 , 27.9824819 , 34.23052479,\n",
       "       40.07167649, 45.1518751 , 49.76793398, 53.33421219, 56.27584439,\n",
       "       58.07281341, 58.74456718, 58.44840958, 56.56046452, 53.60165294,\n",
       "       48.87309243, 42.71364546, 34.88959056, 25.10785755, 13.59392378])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steepest_descent(A, b, x0, tol=1e-6, max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OIflbEdZym5"
   },
   "source": [
    "## Conjugate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-YjrnuhSbwRJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conjugate_gradient(A, b, x0, tol=1e-6, max_iter=100):\n",
    "\n",
    "\n",
    "  # Set the initial residual and search direction\n",
    "    r = b - np.dot(A, x0)\n",
    "    p = r\n",
    "\n",
    "    for i in range(max_iter):\n",
    "    # Calculate the step size alpha\n",
    "        alpha = np.dot(r, r) / np.dot(p, np.dot(A, p))\n",
    "    # Update the solution vector x\n",
    "        x0 = x0 + alpha * p\n",
    "    # Update the residual vector r\n",
    "        r_prev = r\n",
    "        r = b - np.dot(A, x0)\n",
    "    # Check if the residual is below the convergence threshold\n",
    "        if np.linalg.norm(r) < tol:\n",
    "            break\n",
    "    # Calculate beta using the Hestenes-Stiefel method\n",
    "        beta = np.dot(r, r) / np.dot(r_prev, r_prev)\n",
    "    # Update the search direction p\n",
    "        p = r + beta * p\n",
    "\n",
    "        return(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK7j9_SVlG2W",
    "outputId": "33d03df3-a6b0-4849-f7c0-c949c5e3f4cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.9625,  2.325 ,  2.9875,  3.65  ,  4.3125,  4.975 ,  5.6375,\n",
       "        6.3   ,  6.9625,  7.625 ,  8.2875,  8.95  ,  9.6125, 10.275 ,\n",
       "       10.9375, 11.6   , 12.2625, 12.925 , 13.5875,  7.625 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjugate_gradient(A, b, x0, tol=1e-6, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNhv5XcCdL0v",
    "outputId": "268535b5-2201-47ab-cf77-47684c706147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.33333333, 14.56666667, 21.6       , 28.33333333, 34.66666667,\n",
       "       40.5       , 45.73333333, 50.26666667, 54.        , 56.83333333,\n",
       "       58.66666667, 59.4       , 58.93333333, 57.16666667, 54.        ,\n",
       "       49.33333333, 43.06666667, 35.1       , 25.33333333, 13.66666667])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVgN4indmLNR"
   },
   "source": [
    "\n",
    "Note that these methos assume that the matrix A is symmetric and positive definite, which is a requirement to converge. If the matrix A is not symmetric and positive definite, methods may not converge or may converge to a non-optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fw8vlz36e1iO"
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "def is_pos_def(A):\n",
    "    \"\"\"check if a matrix is symmetric positive definite\"\"\"\n",
    "    return np.all(np.linalg.eigvals(A) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1zNpOABe8Ll",
    "outputId": "1cba045c-2169-4e76-c80c-39558c051b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these methods assume that the matrix A is symmetric and positive definite, which is a\n",
    "requirement to converge. If the matrix A is not symmetric and positive definite, methods may not\n",
    "converge or may converge to a non-optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODwtaGKjfnvK",
    "outputId": "3b6343e0-245a-49cc-cf93-5b36496f9704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 ms, sys: 0 ns, total: 1.05 ms\n",
      "Wall time: 1.06 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.33333333, 14.56666667, 21.6       , 28.33333333, 34.66666667,\n",
       "       40.5       , 45.73333333, 50.26666667, 54.        , 56.83333333,\n",
       "       58.66666667, 59.4       , 58.93333333, 57.16666667, 54.        ,\n",
       "       49.33333333, 43.06666667, 35.1       , 25.33333333, 13.66666667])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "conjugate_gradient(A, b, x0, tol=1e-6, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ahPMDxNfrT7",
    "outputId": "3dc757b8-f3e7-4c24-dd70-0073d58f1272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 ms, sys: 0 ns, total: 2.49 ms\n",
      "Wall time: 2.67 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.34654432, 17.35080654, 24.88373093, 33.13149786, 40.4143787 ,\n",
       "       46.64309863, 53.34235316, 57.58126325, 62.30889354, 65.06857406,\n",
       "       66.76757378, 67.73360092, 66.37753513, 64.54347088, 60.35827484,\n",
       "       55.0130042 , 47.72378378, 38.6934217 , 27.77265083, 14.90418828])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "steepest_descent(A, b, x0, tol=1e-6, max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from above time results, Conjugate Gradient Method is faster than Steepest Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
